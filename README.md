# ğŸ“– Documentation for project: **Detection of fake Ukrainian news**

### ğŸ“Œ Description:
This is a student project for the **Machine Learning** course, aimed at developing an application for detecting fake news.

### ğŸ¯ The main goal:
Create a machine learning model capable of analyzing Ukrainian news texts and determining their authenticity.

# âœ…Approach
### 1ï¸âƒ£ Data Collection
- Searching for available Ukrainian news datasets in internet
- Downloading datasets (*if we find it*)
- Analyze the data structure and identify key fields (**URL, title, text, source, date**). What sources the news is from, etc.

### 2ï¸âƒ£ Data Preprocessing
- Extracting relevant information for further work. For example:
   * Title
   * Text of news
   * Time when the news was published
   * Additional info that will be needed later
- Removing duplicates and unnecessary data
- Analyzing data distribution and identifying news sources. We divide them into the following
   - **Sources we trust:**
      * [**TSN**](https://tsn.ua/news)
      * [**BBC**](https://www.bbc.com/ukrainian)
      * [**Ğ¡ÑƒÑĞ¿Ñ–Ğ»ÑŒĞ½Ğµ**](https://t.me/suspilnenews)
      * [**ÒĞ Ğ£ĞĞ¢**](https://t.me/gruntmedia)
      * [**STERNENKO**](https://t.me/ssternenko)
      * [**Ğ›Ğ°Ñ‡ĞµĞ½ Ğ¿Ğ¸ÑˆĞµ**](https://t.me/lachentyt)
   - **Sources we do not trust:**
      * [**Ğ’Ğ¾ĞºÑ Ğ£ĞºÑ€Ğ°Ñ—Ğ½Ğ°**](https://voxukraine.org/category/voks-informue)
      * [**Ğ’Ğ¾Ğ¹Ğ½Ğ° Ñ Ñ„ĞµĞ¹ĞºĞ°Ğ¼Ğ¸**](https://t.me/warfakes)
- Balancing classes (if necessary)

### 3ï¸âƒ£ Model Development
- Selection of a **machine learning algorithm** by the selection method.
- Training of the selected algorithm
- Determining its performance.
- Optimization of hyperparameters to increase the accuracy.
- (Optional) If the approach fails, consider:
   - Using an LLM model.
   - Falling back to GPT-based classification.

# ğŸ“Š Datasets Used

### 1ï¸âƒ£ **Ukrainian Fake and True News**
- Source: [Kaggle](https://www.kaggle.com/datasets/zepopo/ukrainian-fake-and-true-news)
- Description: Contains Fake and True news about Russo-Ukrainian war

### 2ï¸âƒ£ **Ukrainian News**
- Source: [Hugging Face](https://huggingface.co/datasets/zeusfsx/ukrainian-news)
- Description: A dataset of news articles downloaded from various Ukrainian websites and Telegram channels

* **Divided the Dataset from Hugging Face**
   - Source: [Filemail](https://bebra-bebrynka.filemail.com/d/rhfwkzhvbwtwmen)
   - Description: A modified version of the Hugging Face dataset, divided into 22 parts, each containing 1 million rows.
   - Using this [code](split_all_dataset_from_hf.py) for that purpose.

# ğŸš€ Development Journey
## ğŸ“Œ Part about our project success story
**1ï¸âƒ£ 2025-02-03** â€“ Team Formation

**ğŸ’¡2025-02-06** â€“ Development of the Idea to Tackle Disinformation

**ğŸ”2025-02-14** â€“ Searched for datasets with Ukrainian news, but failed

**ğŸ“°2025-02-16** â€“ The first try to scrap news from **[TSN.ua](https://tsn.ua/news)**
 - News is scrapping very slowly so we decided to find other ways of collecting data

**ğŸ¤”2025-02-17**
 - Came across the problem of labeling data (how to label a huge amount of data (fake or real) by ourselves?)
 - The second try to find the dataset and already successful. (We found [`ukrainian-news`](https://huggingface.co/datasets/zeusfsx/ukrainian-news) on HuggingFace and
  [`Ukrainian News`](https://www.kaggle.com/datasets/zepopo/ukrainian-fake-and-true-news) on Kaggle)
- We consider the idea of labeling data this way: Choose sources we trust and mark that news as '**real**', then choose some suspicious sources and mark them as '**fake**'

**ğŸ—‚ï¸2025-02-18**
 - Trying to download [`ukrainian-news`](https://huggingface.co/datasets/zeusfsx/ukrainian-news) dataset on HuggingFace but came across of lacking resources (the dataset is really large (*22 milion rows*) and takes **a lot of RAM to process**). So we decide to divide the dataset into 23 subsets for better processing.


**ğŸ“Œ Next Steps... Stay Tuned!**